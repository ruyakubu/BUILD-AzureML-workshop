{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684434890868
        }
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Authenticated ML Client session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684434892946
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: ./config.json\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "registry_name = 'azureml'\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client =  MLClient.from_config(credential=credential)\n",
        "\n",
        "ml_client_registry = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group_name=ml_client.resource_group_name,\n",
        "    registry_name=registry_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1684434894366
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model_name = 'hospital_readmission_model'\n",
        "model = ml_client.models.get(name=model_name, label='latest')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Identify numeric and categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1684434894526
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "categorical columns:  ['race', 'gender', 'age', 'discharge_destination', 'admission_source', 'primary_diagnosis', 'max_glu_serum', 'A1Cresult', 'insulin', 'diabetes_Med_prescribe']\n",
            "numerical field:  Index(['num_lab_procedures', 'num_medications', 'num_procedures',\n",
            "       'number_diagnoses', 'prior_emergency', 'prior_inpatient',\n",
            "       'prior_outpatient', 'time_in_hospital'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "target_column = 'readmit_status'\n",
        "\n",
        "def get_categorical_numerical_data(dataset):\n",
        "    dataset = dataset.drop([target_column], axis = 1)  \n",
        "    categorical = []\n",
        "    for col, value in dataset.iteritems():\n",
        "        if value.dtype == 'object' or value.dtype == 'bool':\n",
        "            categorical.append(col)\n",
        "    numerical = dataset.columns.difference(categorical)\n",
        "    return categorical, numerical\n",
        "\n",
        "# get categorical and numerical fields from training data\n",
        "train_data = pd.read_parquet('data/training_data.parquet')\n",
        "categorical, numerical = get_categorical_numerical_data(train_data)\n",
        "print('categorical columns: ',  categorical)\n",
        "print('numerical field: ', numerical)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the dashboard components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1684434894673
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "label = 'latest'\n",
        "\n",
        "rai_constructor_component = ml_client_registry.components.get(\n",
        "    name='microsoft_azureml_rai_tabular_insight_constructor', label=label\n",
        ")\n",
        "\n",
        "# We get latest version and use the same version for all components\n",
        "version = rai_constructor_component.version\n",
        "\n",
        "rai_explanation_component = ml_client_registry.components.get(\n",
        "    name='microsoft_azureml_rai_tabular_explanation', version=version\n",
        ")\n",
        "\n",
        "rai_erroranalysis_component = ml_client_registry.components.get(\n",
        "    name='microsoft_azureml_rai_tabular_erroranalysis', version=version\n",
        ")\n",
        "\n",
        "rai_gather_component = ml_client_registry.components.get(\n",
        "    name='microsoft_azureml_rai_tabular_insight_gather', version=version\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the job to create the RAI dashboard insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1684434894896
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from azure.ai.ml import dsl\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "compute_name = 'trainingcompute'\n",
        "rai_hospital_version_string = '1'\n",
        "expected_model_id = f'{model_name}:{model.version}'\n",
        "azureml_model_id = f'azureml:{expected_model_id}'\n",
        "\n",
        "@dsl.pipeline(\n",
        "        compute=compute_name,\n",
        "        description='RAI computation on hospital readmit classification data',\n",
        "        experiment_name= 'RAI_hospital_Classification_RAIInsights_Computation_{rai_hospital_version_string}',\n",
        "    )\n",
        "def rai_classification_pipeline(\n",
        "        target_column_name,\n",
        "        training_data,\n",
        "        testing_data\n",
        "    ):\n",
        "        # Initiate the RAIInsights\n",
        "        create_rai_job = rai_constructor_component(\n",
        "            title='RAI Dashboard',\n",
        "            task_type='classification',\n",
        "            model_info=expected_model_id,\n",
        "            model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),            \n",
        "            train_dataset=training_data,\n",
        "            test_dataset=testing_data,\n",
        "            target_column_name=target_column_name,\n",
        "            categorical_column_names=json.dumps(categorical),\n",
        "        )\n",
        "        create_rai_job.set_limits(timeout=2400)\n",
        "        \n",
        "        # Add an explanation\n",
        "        explain_job = rai_explanation_component(\n",
        "            comment='Explanation for hospital remitted less than 30days  classification',\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
        "        )\n",
        "        explain_job.set_limits(timeout=2400)\n",
        "        \n",
        "        # Add error analysis\n",
        "        erroranalysis_job = rai_erroranalysis_component(\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
        "        )\n",
        "        erroranalysis_job.set_limits(timeout=2400)\n",
        "\n",
        "        # Combine everything\n",
        "        rai_gather_job = rai_gather_component(\n",
        "            constructor=create_rai_job.outputs.rai_insights_dashboard,\n",
        "            insight_1=explain_job.outputs.explanation,\n",
        "            insight_4=erroranalysis_job.outputs.error_analysis,\n",
        "        )\n",
        "        rai_gather_job.set_limits(timeout=2400)\n",
        "\n",
        "        rai_gather_job.outputs.dashboard.mode = 'upload'\n",
        "        rai_gather_job.outputs.ux_json.mode = 'upload'\n",
        "\n",
        "        return {\n",
        "            'dashboard': rai_gather_job.outputs.dashboard,\n",
        "            'ux_json': rai_gather_job.outputs.ux_json\n",
        "        }"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Pipeline job submission and status check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1684434895045
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import PipelineJob\n",
        "import webbrowser\n",
        "import time\n",
        "\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
        "    assert created_job is not None\n",
        "\n",
        "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\n",
        "        time.sleep(30)\n",
        "        created_job = ml_client.jobs.get(created_job.name)\n",
        "        print('Latest status : {0}'.format(created_job.status))\n",
        "\n",
        "\n",
        "    # open the pipeline in web browser\n",
        "    webbrowser.open(created_job.services['Studio'].endpoint)\n",
        "    \n",
        "    #assert created_job.status == 'Completed'\n",
        "    return created_job"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run job to create the RAI dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1684435200792
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latest status : Running\n",
            "Latest status : Running\n",
            "Latest status : Running\n",
            "Latest status : Running\n",
            "Latest status : Running\n",
            "Latest status : Running\n",
            "Latest status : Running\n",
            "Latest status : Running\n",
            "Latest status : Running\n",
            "Latest status : Completed\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "from azure.ai.ml import Output\n",
        "\n",
        "hospital_train_parquet = Input(\n",
        "    type='uri_file', path='data/training_data.parquet', mode='download'\n",
        ")\n",
        "\n",
        "hospital_test_parquet = Input(\n",
        "    type='uri_file', path='data/testing_data.parquet', mode='download'\n",
        ")\n",
        "\n",
        "# Pipeline to construct the RAI Insights\n",
        "insights_pipeline_job = rai_classification_pipeline(\n",
        "    target_column_name=target_column,\n",
        "    training_data=hospital_train_parquet,\n",
        "    testing_data=hospital_test_parquet,\n",
        ")\n",
        "\n",
        "# Workaround to enable the download\n",
        "rand_path = str(uuid.uuid4())\n",
        "insights_pipeline_job.outputs.dashboard = Output(\n",
        "    path=f'azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/',\n",
        "    mode='upload',\n",
        "    type='uri_folder',\n",
        ")\n",
        "insights_pipeline_job.outputs.ux_json = Output(\n",
        "    path=f'azureml://datastores/workspaceblobstore/paths/{rand_path}/ux_json/',\n",
        "    mode='upload',\n",
        "    type='uri_folder',\n",
        ")\n",
        "\n",
        "\n",
        "# submit pipeline\n",
        "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
